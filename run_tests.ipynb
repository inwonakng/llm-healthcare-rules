{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = open('openai_api_key.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_type = 'use_model_output'\n",
    "task_type = 'use_original_doc'\n",
    "logic_type = 'N3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    open(prompt_path).read()\n",
    "    for prompt_path in sorted(Path(f'prompts/{task_type}/{logic_type}').glob(f'*.txt'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 Complete\n",
      "Task 2 Complete\n",
      "Task 3 Complete\n",
      "Test 1 complete\n",
      "Task 1 Complete\n",
      "Task 2 Complete\n",
      "Task 3 Complete\n",
      "Test 2 complete\n",
      "Task 1 Complete\n",
      "Task 2 Complete\n",
      "Task 3 Complete\n",
      "Test 3 complete\n"
     ]
    }
   ],
   "source": [
    "all_outputs = {}\n",
    "output_dir = Path('outputs')/task_type/logic_type\n",
    "\n",
    "for test_idx,test_file in enumerate(sorted(Path('tests').glob('*.txt'))):\n",
    "    test_input = open(test_file).read()\n",
    "    model_output = test_input\n",
    "    test_output_dir = output_dir / test_file.stem\n",
    "    test_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    test_outputs = []\n",
    "\n",
    "    for task_idx, base_prompt in enumerate(prompts):\n",
    "        if task_type == 'use_original_doc':\n",
    "            prompt = '{}\\n\"\"\"{}\"\"\"'.format(base_prompt, test_input)\n",
    "        elif task_type == 'use_model_output':\n",
    "            prompt = '{}\\n\"\"\"{}\"\"\"'.format(base_prompt, model_output)\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "        )\n",
    "        model_output = response['choices'][0]['message']['content']\n",
    "        test_outputs.append(model_output)\n",
    "\n",
    "        print(f'Task {task_idx+1} Complete')\n",
    "        \n",
    "        # save output file\n",
    "        open(test_output_dir / f'task_{test_idx+1}.txt', 'w').write(model_output)\n",
    "    print(f'Test {test_idx+1} complete')\n",
    "    print('-----------------')\n",
    "    all_outputs[test_file.stem] = test_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-healthcare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
